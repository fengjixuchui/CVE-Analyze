from distutils.command.clean import clean
from py2neo import Graph,Node,Relationship
import json
import os
from py2neo.matching import *


KGraph = Graph(
    "http://nju.csuncle.com:7474", 
    auth=("neo4j","wlm94929")
)



##### TF-IDF####
# from sklearn.feature_extraction.text import TfidfVectorizer
# matcher = NodeMatcher(KGraph)
# CAPEC_result = matcher.match('CAPEC').all()
# ATTACK_result = matcher.match('ATT&CK').all()

# CAPEC_cnt=len(CAPEC_result)
# ATTACK_cnt=len(ATTACK_result)

# corpus_id=[]
# corpus=[]

# for capec in CAPEC_result:
#     corpus_id.append(capec["CAPEC_ID"])
#     corpus.append(capec["Description"])

# for attack in ATTACK_result:
#     corpus_id.append(attack["TTP_id_unique"])
#     corpus.append(attack["Description"])

# vect = TfidfVectorizer(min_df=1, stop_words="english")                                                                                                                                                                                                   
# tfidf = vect.fit_transform(corpus)                                                                                                                                                                                                                       
# pairwise_similarity = tfidf * tfidf.T 
# values=pairwise_similarity.toarray()

# matcher=RelationshipMatcher(KGraph)
# results=matcher.match(None, r_type='CAPEC2ATTACK').all()

# r=[]
# y=[]

# for rl in results:
#     r.append(1)

#     rl0_id=rl.nodes[0]["CAPEC_ID"]
#     rl0_index=corpus_id.index(rl0_id)
#     rl1_id=rl.nodes[1]["TTP_id_unique"]
#     rl1_index=corpus_id.index(rl1_id)
#     rl01_similarity=values[rl0_index][rl1_index]

#     total=0
#     for j in range(ATTACK_cnt):
#         if values[rl0_index][j+CAPEC_cnt]>rl01_similarity:
#             total+=1

#     if total<=3:
#         y.append(1)
#     else:
#         y.append(0)



# import numpy as np
# from sklearn.metrics import classification_report

# y_true= np.array(r)
# y_pred=np.array(y)

# print(classification_report(y_true,y_pred,digits=5))


########Doc2vec##########
import gensim
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from nltk.tokenize import word_tokenize
from gensim.models.doc2vec import Doc2Vec
# import nltk

# nltk.download('punkt')

matcher = NodeMatcher(KGraph)
CAPEC_result = matcher.match('CAPEC').all()
ATTACK_result = matcher.match('ATT&CK').all()

CAPEC_cnt=len(CAPEC_result)
ATTACK_cnt=len(ATTACK_result)

corpus_id=[]
corpus=[]

for capec in CAPEC_result:
    corpus_id.append(capec["CAPEC_ID"])
    corpus.append(capec["Description"])

for attack in ATTACK_result:
    corpus_id.append(attack["TTP_id_unique"])
    corpus.append(attack["Description"])

tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(corpus)]

model = gensim.models.doc2vec.Doc2Vec(vector_size=30, min_count=2, epochs=80)
model.build_vocab(tagged_data)
model.train(tagged_data, total_examples=model.corpus_count, epochs=80)
model.save("d2v.model")

model = Doc2Vec.load("d2v.model")


matcher=RelationshipMatcher(KGraph)
results=matcher.match(None, r_type='CAPEC2ATTACK').all()

r=[]
y=[]

for rl in results:
    r.append(1)

    rl0_id=rl.nodes[0]["CAPEC_ID"]
    rl0_index=corpus_id.index(rl0_id)
    rl1_id=rl.nodes[1]["TTP_id_unique"]
    rl1_index=corpus_id.index(rl1_id)

    flag=False
    similar_doc = model.docvecs.most_similar(rl0_id)
    for item in similar_doc:
        if rl1_index==int(item[0]):
            flag=True
            

    if flag:
        y.append(1)
    else:
        y.append(0)


import numpy as np
from sklearn.metrics import classification_report

y_true= np.array(r)
y_pred=np.array(y)

print(classification_report(y_true,y_pred,digits=5))
